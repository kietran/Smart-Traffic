name: nano
services:
  mongo:
    image: mongo
    container_name: nano-mongo
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin
      MONGO_INITDB_DATABASE: nano
    ports:
      - 27010:27017
    volumes:
      - ./mongo/mongo-drop.js:/docker-entrypoint-initdb.d/mongo-drop.js:ro
      - ./mongo/mongo-up.js:/docker-entrypoint-initdb.d/mongo-up.js:ro
  mongo-express:
    container_name: nano-mongo-express
    image: mongo-express
    restart: always
    ports:
      - 8005:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: admin
      ME_CONFIG_MONGODB_ADMINPASSWORD: admin
      ME_CONFIG_MONGODB_URL: mongodb://admin:admin@mongo:27017/
      ME_CONFIG_BASICAUTH: false
  redis:
    image: redis:latest
    restart: always
    container_name: nano-redis
    ports:
        - "${REDIS_PORT:-6379}:6379"
    volumes:
        - ./redis/data:/root/redis
        - /etc/redis/redis.conf:/usr/local/etc/redis/redis.conf
    environment:
        - REDIS_PORT=${REDIS_PORT:-6379}
        - REDIS_DATABASES=0
    networks:
        - nano

  ai-streaming:
    image: ai-streaming:v1.0.0
    build:
      context: ..
      dockerfile: deployment/ai-streaming/Dockerfile
    container_name: ai-streaming
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    restart: always
    volumes:
      - ../src/ai-streaming/:/app/src/ai-streaming/
      - ../.env:/app/.env
      - "/etc/timezone:/etc/timezone:ro"
      - "/etc/localtime:/etc/localtime:ro"
    command: uv run src/ai-streaming/sub.py
    tty: true
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
    networks:
      - nano
  ai-services:
    command: uv run src/ai_services/main.py
    image: ai-services:v1.0.0
    build:
        context: ..
        dockerfile: deployment/ai_services/Dockerfile
    container_name: nano-ai-services
    working_dir: /app
    restart: unless-stopped
    volumes:
        - ../protoc:/app/protoc/
        - ../src/ai_services/:/app/src/ai_services/
        - ../.env:/app/.env
        - "/etc/timezone:/etc/timezone:ro"
        - "/etc/localtime:/etc/localtime:ro"
    networks:
        - nano
    logging:
        driver: "json-file"
        options:
            max-size: "50m"
    tty: true
    deploy:
        resources:
            reservations:
                devices:
                    - driver: nvidia
                      count: all
                      capabilities: [gpu]

  api:
    container_name: nano-api
    image: api:v1.0.0
    working_dir: /app
    build:
        context: ..
        dockerfile: deployment/api/Dockerfile
    ports:
        - "${API_PORT:-8001}:${API_PORT:-8001}"
    restart: unless-stopped
    command: uv run src/api/app.py
    tty: true
    logging:
        driver: "json-file"
        options:
            max-size: "50m"
    volumes:
        - ../src/api/:/app/src/api/
        - "/etc/timezone:/etc/timezone:ro"
        - "/etc/localtime:/etc/localtime:ro"
        - ../.env:/app/.env
    networks:
        - nano
    depends_on:
        - mongo

  minio:
      container_name: nano-minio
      ports:
          - "${MINIO_PORT:-9000}:9000"
          - "${MINIO_CONSOLE_PORT:-9001}:9001"
      image: quay.io/minio/minio:latest
      command: server /data --console-address ":9001"
      environment:
          - MINIO_ROOT_USER=${MINIO_USERNAME:-meme}
          - MINIO_ROOT_PASSWORD=${MINIO_PASSWORD:-meme@123}

      restart: always
      user: root:root
      volumes:
          - ./minio/data:/data:rw,z
      networks:
          - nano
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: nano-kafka-console
    ports:
      - "6789:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
    depends_on:
      - kafka
    networks:
      - nano
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka
    container_name: nano-kafka
    ports:
        - "9089:9092"
    environment:
        KAFKA_BROKER_ID: 1
        KAFKA_NODE_ID: 1
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
        KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:29092,PLAINTEXT_HOST://100.112.243.28:9089"
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
        KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
        KAFKA_PROCESS_ROLES: "broker,controller"
        KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"
        KAFKA_LISTENERS: "PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092"
        KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
        KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
        KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"

        CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
        KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 1000
        KAFKA_LOG_RETENTION_MINUTES: 10
    restart: unless-stopped
    logging:
        driver: "json-file"
        options:
            max-size: "50m"
    networks:
        - nano
  hls-stream:
    command: bash -c "cd /app/hls-stream && uv run api.py"
    image: hls-stream:v0.1.0
    build:
      context: ..
      dockerfile: deployment/hls-stream/Dockerfile
    runtime: nvidia
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,video,utility
      GPU_VCODEC: h264_nvenc
      GPU_PRESET: p1
      GPU_TUNE: ull
      GPU_VIDEO_BITRATE: 500k
      GPU_MAXRATE: 1M
      GPU_BUFSIZE: 1M
    container_name: nano-hls-stream
    working_dir: /app
    env_file:
      - ../.env
    restart: unless-stopped
    volumes:
      - ../src/hls-stream:/app/hls-stream/
      - "/etc/timezone:/etc/timezone:ro"
      - "/etc/localtime:/etc/localtime:ro"

    ports:
      - "3597:3597"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
    tty: true
networks:
  nano:
    name: nano
    driver: bridge